{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BPR\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import time\n",
    "from functools import partial \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../gamedata/original_dataset/\"\n",
    "DATA_FILE = \"dd_event_schemas.csv\"\n",
    "DATA_FOR_BPR = \"data_for_BPR.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "data = pd.read_csv(DATA_DIR+DATA_FILE)\n",
    "gameid = data['gameid'].drop_duplicates()\n",
    "gameid_list = []\n",
    "gameid_list = list(gameid)\n",
    "gameid2newid = {old:new+1 for new, old in enumerate(gameid_list)}\n",
    "data['new_game_id'] = data['gameid'].map(gameid2newid)\n",
    "\n",
    "events = data['eventname'].drop_duplicates()\n",
    "events_list = list(events)\n",
    "events2id = {old:new+1 for new,old in enumerate(events_list)}\n",
    "data['new_event_id'] = data['eventname'].map(events2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(DATA_DIR+'data_for_BPR.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    game_events = defaultdict(set)\n",
    "    game_count = -1\n",
    "    event_count = -1\n",
    "    with open(data_path,'r') as f:\n",
    "        header_line = next(f)\n",
    "        for line in f.readlines():\n",
    "            _, _, _, _, _, _, gameid, eventid = line.split(\",\")\n",
    "            gameid = int(gameid)\n",
    "            eventid = int(eventid)\n",
    "            #print(u,i)\n",
    "            game_events[gameid].add(eventid)\n",
    "            game_count = max(gameid, game_count)\n",
    "            event_count = max(eventid, event_count)\n",
    "    print (\"game_count:\", game_count)\n",
    "    print (\"event_count:\", event_count)\n",
    "    #return max_u_id, max_i_id, user_ratings\n",
    "    return game_count,event_count,game_events\n",
    "    \n",
    "\n",
    "#data_path = os.path.join('D:\\\\tmp\\\\ml-100k', 'u.data')\n",
    "#user_count, item_count, user_ratings = load_data(data_path)\n",
    "game_count,event_count,game_events_dict = load_data(DATA_DIR+DATA_FOR_BPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for testing\n",
    "def generate_test(game_events_dict):\n",
    "    user_test = dict()\n",
    "    for u, i_list in game_events_dict.items():\n",
    "        user_test[u] = random.sample(game_events_dict[u], 1)[0]\n",
    "    return user_test\n",
    "\n",
    "test_set = generate_test(game_events_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate dataset for training\n",
    "def generate_train_batch(game_events_dict, test_set, event_count, batch_size=512):\n",
    "    t = []\n",
    "    for b in range(batch_size):\n",
    "        u = random.sample(game_events_dict.keys(), 1)[0]\n",
    "        i = random.sample(game_events_dict[u], 1)[0]\n",
    "        while i == test_set[u]:\n",
    "            i = random.sample(game_events_dict[u], 1)[0]\n",
    "        \n",
    "        j = random.randint(1, event_count)\n",
    "        while j in game_events_dict[u]:\n",
    "            j = random.randint(1, event_count)\n",
    "        t.append([u, i, j])\n",
    "    return numpy.asarray(t)\n",
    "\n",
    "#train_set = generate_train_batch(game_events_dict,test_set,event_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bpr_mf(game_count, event_count, hidden_dim):\n",
    "    u = tf.placeholder(tf.int32, [None])\n",
    "    i = tf.placeholder(tf.int32, [None])\n",
    "    j = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        user_emb_w = tf.get_variable(\"user_emb_w\", [game_count+1, hidden_dim], \n",
    "                            initializer=tf.random_normal_initializer(0, 0.1))\n",
    "        item_emb_w = tf.get_variable(\"item_emb_w\", [event_count+1, hidden_dim], \n",
    "                                initializer=tf.random_normal_initializer(0, 0.1))\n",
    "        \n",
    "        u_emb = tf.nn.embedding_lookup(user_emb_w, u)\n",
    "        i_emb = tf.nn.embedding_lookup(item_emb_w, i)\n",
    "        j_emb = tf.nn.embedding_lookup(item_emb_w, j)\n",
    "    \n",
    "    # MF predict: u_i > u_j\n",
    "    x = tf.reduce_sum(tf.multiply(u_emb, (i_emb - j_emb)), 1, keep_dims=True)\n",
    "    \n",
    "    # AUC for one user:\n",
    "    # reasonable iff all (u,i,j) pairs are from the same user\n",
    "    # \n",
    "    # average AUC = mean( auc for each user in test set)\n",
    "    mf_auc = tf.reduce_mean(tf.to_float(x > 0))\n",
    "    \n",
    "    l2_norm = tf.add_n([\n",
    "            tf.reduce_sum(tf.multiply(u_emb, u_emb)), \n",
    "            tf.reduce_sum(tf.multiply(i_emb, i_emb)),\n",
    "            tf.reduce_sum(tf.multiply(j_emb, j_emb))\n",
    "        ])\n",
    "    \n",
    "    regulation_rate = 0.0001\n",
    "    bprloss = regulation_rate * l2_norm - tf.reduce_mean(tf.log(tf.sigmoid(x)))\n",
    "    \n",
    "    train_op = tf.train.GradientDescentOptimizer(0.01).minimize(bprloss)\n",
    "    return u, i, j, mf_auc, bprloss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(), tf.Session() as session:\n",
    "    u, i, j, mf_auc, bprloss, train_op = bpr_mf(game_count, event_count, 20)\n",
    "    session.run(tf.initialize_all_variables())\n",
    "    for epoch in range(1, 4):\n",
    "        _batch_bprloss = 0\n",
    "        for k in range(1, 5000): # uniform samples from training set\n",
    "            uij = generate_train_batch(game_events_dict, test_set, event_count)\n",
    "\n",
    "            _bprloss, _train_op = session.run([bprloss, train_op], \n",
    "                                feed_dict={u:uij[:,0], i:uij[:,1], j:uij[:,2]})\n",
    "            _batch_bprloss += _bprloss\n",
    "        \n",
    "        print (\"epoch: \", epoch)\n",
    "        print (\"bpr_loss: \", _batch_bprloss / k)\n",
    "        print (\"_train_op\")\n",
    "\n",
    "        game_count = 0\n",
    "        _auc_sum = 0.0\n",
    "\n",
    "        # each batch will return only one user's auc\n",
    "        for t_uij in generate_test_batch(game_events_dict, test_set, event_count):\n",
    "\n",
    "            _auc, _test_bprloss = session.run([mf_auc, bprloss],\n",
    "                                    feed_dict={u:t_uij[:,0], i:t_uij[:,1], j:t_uij[:,2]}\n",
    "                                )\n",
    "            game_count += 1\n",
    "            _auc_sum += _auc\n",
    "        print (\"test_loss: \", _test_bprloss, \"test_auc: \", _auc_sum/game_count)\n",
    "        print (\"\")\n",
    "    variable_names = [v.name for v in tf.trainable_variables()]\n",
    "    values = session.run(variable_names)\n",
    "    for k,v in zip(variable_names, values):\n",
    "        print(\"Variable: \", k)\n",
    "        print(\"Shape: \", v.shape)\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session1 = tf.Session()\n",
    "u1_dim = tf.expand_dims(values[0][0], 0)\n",
    "u1_all = tf.matmul(u1_dim, values[1],transpose_b=True)\n",
    "result_1 = session1.run(u1_all)\n",
    "print (result_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
